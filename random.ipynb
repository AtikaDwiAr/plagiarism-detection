{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02d847cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 1: Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier # Import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7b4171d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                filename   label  bow_abandon  bow_aber  \\\n",
      "0  preprocessed_source-document00086.txt  source            0         0   \n",
      "1  preprocessed_source-document00087.txt  source           21         0   \n",
      "2  preprocessed_source-document00088.txt  source            2         0   \n",
      "3  preprocessed_source-document00089.txt  source            2         0   \n",
      "4  preprocessed_source-document00090.txt  source            0         0   \n",
      "\n",
      "   bow_abide  bow_ability  bow_able  bow_abner  bow_abode  bow_abound  ...  \\\n",
      "0          0            0         0          0          0           0  ...   \n",
      "1          6            1        11          0          2           3  ...   \n",
      "2          0            0         3          0          0           2  ...   \n",
      "3          1            2         9          0          0           0  ...   \n",
      "4          0            1         1          0          0           0  ...   \n",
      "\n",
      "   bert_374  bert_375  bert_376  bert_377  bert_378  bert_379  bert_380  \\\n",
      "0  0.025689  0.004827 -0.013753  0.088099  0.026668  0.048113  0.147617   \n",
      "1  0.002385  0.087415  0.051589  0.132519  0.015237  0.011092  0.098759   \n",
      "2 -0.032123  0.058444  0.006868  0.149404 -0.054011  0.026080  0.126716   \n",
      "3 -0.013282 -0.038822 -0.014967  0.074671  0.028954 -0.036840  0.131572   \n",
      "4  0.024597  0.001248  0.041121  0.107749  0.022889  0.046890  0.127271   \n",
      "\n",
      "   bert_381  bert_382  bert_383  \n",
      "0  0.015009 -0.026309 -0.089825  \n",
      "1 -0.008328 -0.022615 -0.096620  \n",
      "2  0.028469  0.024714 -0.165328  \n",
      "3  0.061069 -0.041462 -0.068454  \n",
      "4  0.013901 -0.029564 -0.043363  \n",
      "\n",
      "[5 rows x 10486 columns]\n",
      "       bow_abandon    bow_aber   bow_abide  bow_ability    bow_able  \\\n",
      "count   200.000000  200.000000  200.000000   200.000000  200.000000   \n",
      "mean      2.105000    2.645000    0.535000     2.055000    8.310000   \n",
      "std       4.596697   31.928925    1.513349     5.894549   13.882996   \n",
      "min       0.000000    0.000000    0.000000     0.000000    0.000000   \n",
      "25%       0.000000    0.000000    0.000000     0.000000    0.000000   \n",
      "50%       0.000000    0.000000    0.000000     0.000000    2.000000   \n",
      "75%       2.000000    0.000000    0.000000     2.000000   11.000000   \n",
      "max      29.000000  449.000000   15.000000    51.000000   83.000000   \n",
      "\n",
      "        bow_abner   bow_abode  bow_abound  bow_abroad  bow_abruptly  ...  \\\n",
      "count  200.000000  200.000000  200.000000  200.000000    200.000000  ...   \n",
      "mean     1.535000    0.815000    0.500000    1.530000      0.950000  ...   \n",
      "std     20.869992    4.221359    1.215478    3.642173      2.363351  ...   \n",
      "min      0.000000    0.000000    0.000000    0.000000      0.000000  ...   \n",
      "25%      0.000000    0.000000    0.000000    0.000000      0.000000  ...   \n",
      "50%      0.000000    0.000000    0.000000    0.000000      0.000000  ...   \n",
      "75%      0.000000    0.000000    0.000000    2.000000      1.000000  ...   \n",
      "max    295.000000   49.000000    9.000000   34.000000     20.000000  ...   \n",
      "\n",
      "         bert_374    bert_375    bert_376    bert_377    bert_378    bert_379  \\\n",
      "count  200.000000  200.000000  200.000000  200.000000  200.000000  200.000000   \n",
      "mean    -0.011551    0.035100    0.000107    0.089326    0.036724    0.016979   \n",
      "std      0.038558    0.049525    0.050830    0.057907    0.049180    0.044347   \n",
      "min     -0.121385   -0.141363   -0.114197   -0.056113   -0.163237   -0.109347   \n",
      "25%     -0.033637    0.007081   -0.030694    0.052711    0.011853   -0.008727   \n",
      "50%     -0.012417    0.035633   -0.004684    0.089155    0.034440    0.015049   \n",
      "75%      0.015801    0.058471    0.025726    0.119675    0.065146    0.042721   \n",
      "max      0.138190    0.313445    0.274945    0.346513    0.254012    0.197847   \n",
      "\n",
      "         bert_380    bert_381    bert_382    bert_383  \n",
      "count  200.000000  200.000000  200.000000  200.000000  \n",
      "mean     0.098134   -0.005490   -0.008287   -0.054491  \n",
      "std      0.061202    0.058163    0.047073    0.046363  \n",
      "min     -0.098963   -0.393321   -0.209343   -0.181611  \n",
      "25%      0.061709   -0.033150   -0.035587   -0.079092  \n",
      "50%      0.094067    0.001996   -0.012263   -0.059419  \n",
      "75%      0.135485    0.028660    0.019142   -0.033371  \n",
      "max      0.378398    0.120757    0.176844    0.160147  \n",
      "\n",
      "[8 rows x 10484 columns]\n"
     ]
    }
   ],
   "source": [
    "# Section 2: Load Extracted Features Dataset\n",
    "df = pd.read_csv('extracted_features.csv')\n",
    "print(df.head())\n",
    "print(df.describe())\n",
    "# Prepare feature matrix and labels\n",
    "X = df.drop(columns=['label','filename']).values\n",
    "y = df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c8b0d68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 3: Initialize Random Forest Model\n",
    "class RandomForestPlagiarismDetector:\n",
    "    def __init__(self):\n",
    "        self.model = RandomForestClassifier(n_estimators=50, max_depth=10, min_samples_split=5, min_samples_leaf=2, random_state=42)\n",
    "        self.scaler = StandardScaler()\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        # Scale features\n",
    "        self.scaler.fit(X_train)\n",
    "        X_train_scaled = self.scaler.transform(X_train)\n",
    "\n",
    "        # Train the Random Forest model\n",
    "        self.model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        return self.model.predict(X_scaled)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        return self.model.predict_proba(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "54aa5dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6500\n"
     ]
    }
   ],
   "source": [
    "# Section 4: Train the Model\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "detector = RandomForestPlagiarismDetector()\n",
    "detector.train(X_train, y_train) # No need for X_val, y_val during training in this simplified model\n",
    "\n",
    "val_preds = detector.predict(X_val)\n",
    "val_acc = accuracy_score(y_val, val_preds)\n",
    "print(f\"Validation Accuracy: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e0deec5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      source       0.65      0.65      0.65        20\n",
      "  suspicious       0.65      0.65      0.65        20\n",
      "\n",
      "    accuracy                           0.65        40\n",
      "   macro avg       0.65      0.65      0.65        40\n",
      "weighted avg       0.65      0.65      0.65        40\n",
      "\n",
      "Confusion Matrix:\n",
      " [[13  7]\n",
      " [ 7 13]]\n",
      "Random Forest F1-score: 0.6500\n"
     ]
    }
   ],
   "source": [
    "# Section 5: Evaluate Model Performance\n",
    "preds = detector.predict(X_val)\n",
    "print(classification_report(y_val, preds))\n",
    "cm = confusion_matrix(y_val, preds)\n",
    "print('Confusion Matrix:\\n', cm)\n",
    "\n",
    "# Calculate F1-score for comparison\n",
    "f1_rf = f1_score(y_val, preds, average='weighted')\n",
    "print(f\"Random Forest F1-score: {f1_rf:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
